{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"/DATA/zhouyongyu/taac/train_95_7_input.txt\", \"rb+\")\n",
    "(train_creative, train_ad, train_advertiser, train_times, train_product, train_category, train_industry, train_mask, train_gender, train_age) = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/test_95_7_input.txt\", \"rb+\")\n",
    "(test_creative, test_ad, test_advertiser, test_times, test_product, test_category, test_industry, test_mask, test_gender, test_age) = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_from_w2v300_w150.txt\", \"rb+\")\n",
    "creative_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_ad300.txt\", \"rb+\")\n",
    "ad_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_advertiser300.txt\", \"rb+\")\n",
    "advertiser_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_times300.txt\", \"rb+\")\n",
    "times_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_product300.txt\", \"rb+\")\n",
    "product_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_category300.txt\", \"rb+\")\n",
    "category_weight = pickle.load(fp)\n",
    "fp = open(\"/DATA/zhouyongyu/taac/weight_tensor_industry300.txt\", \"rb+\")\n",
    "industry_weight = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "creative_embedding = torch.nn.Embedding.from_pretrained(creative_weight)\n",
    "creative_embedding.weight.requires_grad = False\n",
    "\n",
    "ad_embedding = torch.nn.Embedding.from_pretrained(ad_weight)\n",
    "ad_embedding.weight.requires_grad = False\n",
    "\n",
    "advertiser_embedding = torch.nn.Embedding.from_pretrained(advertiser_weight)\n",
    "advertiser_embedding.weight.requires_grad = False\n",
    "\n",
    "times_embedding = torch.nn.Embedding.from_pretrained(times_weight)\n",
    "times_embedding.weight.requires_grad = False\n",
    "\n",
    "product_embedding = torch.nn.Embedding.from_pretrained(product_weight)\n",
    "product_embedding.weight.requires_grad = False\n",
    "\n",
    "category_embedding = torch.nn.Embedding.from_pretrained(category_weight)\n",
    "category_embedding.weight.requires_grad = False\n",
    "\n",
    "industry_embedding = torch.nn.Embedding.from_pretrained(industry_weight)\n",
    "industry_embedding.weight.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(creative, ad, advertiser, times, product, category, industry, mask, age, gender, batch_size):\n",
    "    # 只是分成多个slices\n",
    "    # slices中储存的为多个索引list（将索引切分为各个batch），如[[0, 1, 2], [3, 4, 5], ...]\n",
    "#     creative = creative[:2000]\n",
    "#     ad = ad[:2000]\n",
    "#     advertiser = advertiser[:2000]\n",
    "#     times = times[:2000]\n",
    "#     product = product[:2000]\n",
    "#     category = category[:2000]\n",
    "#     industry = industry[:2000]\n",
    "#     mask = mask[:2000]\n",
    "#     age = age[:2000]\n",
    "#     gender = gender[:2000]\n",
    "    length = len(creative)\n",
    "    n_batch = int(length / batch_size)\n",
    "    if length % batch_size != 0:\n",
    "        n_batch += 1\n",
    "    # 等分成n_batch份, slices:n_batch*batch_size\n",
    "    # 关于np.split()  https://www.jianshu.com/p/d020afd053bc\n",
    "    slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
    "    # 调整最后一份的length\n",
    "    slices[-1] = slices[-1][:(length - batch_size * (n_batch - 1))]\n",
    "    # slices中储存的为多个索引list（将索引切分为各个batch），如[[0, 1, 2], [3, 4, 5], ...]\n",
    "    # slices是一个二维List，存放了一个batch里面的多个session\n",
    "    return slices, np.array(creative), np.array(ad), np.array(advertiser), np.array(times), np.array(product), np.array(category), np.array(industry), np.array(mask), np.array(age), np.array(gender)\n",
    "\n",
    "def get_slice(creative, ad, advertiser, times, product, category, industry, mask, age, gender, batch_index):\n",
    "    # slice的形式 [[0, 1, 2], [3, 4, 5], ...]\n",
    "    # 每一个slice就是一个batch，遍历slices得到的每一个batch_index就是一个数组，含有该batch内那几条数据的索引\n",
    "    \n",
    "    return creative[batch_index], ad[batch_index], advertiser[batch_index], times[batch_index], product[batch_index], category[batch_index], industry[batch_index], mask[batch_index], age[batch_index], gender[batch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def trans_to_device(variable):\n",
    "    if torch.cuda.is_available():\n",
    "        return variable.cuda()\n",
    "#         return variable\n",
    "    else:\n",
    "        return variable\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, output_size_age, output_size_gender, embedding_dim, hidden_dim, n_layers, bidirectional=True, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(BiLSTM, self).__init__()\n",
    " \n",
    "        self.output_size_age = output_size_age\n",
    "        self.output_size_gender = output_size_gender\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.embedding = embedding\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        # dropout layer\n",
    "#         self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # dropout layer\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.lstm4 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.lstm5 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.lstm6 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.lstm7 = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # dropout layer\n",
    "#         self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        if bidirectional:\n",
    "            self.bn0 = nn.BatchNorm1d(hidden_dim*14, momentum=0.5)\n",
    "            self.fc1 = nn.Linear(hidden_dim*6, 200)\n",
    "            self.bn1 = nn.BatchNorm1d(hidden_dim*14, momentum=0.5)\n",
    "#             self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc_age = nn.Linear(200, output_size_age)\n",
    "            self.bn_age = nn.BatchNorm1d(output_size_age, momentum=0.5)\n",
    "#             self.fc_gender = nn.Linear(hidden_dim*2, output_size_gender)\n",
    "        else:\n",
    "            self.bn0 = nn.BatchNorm1d(hidden_dim*7, momentum=0.5)\n",
    "            self.fc1 = nn.Linear(hidden_dim*7, 400)\n",
    "            \n",
    "            self.bn1 = nn.BatchNorm1d(400, momentum=0.5)\n",
    "            self.fc2 = nn.Linear(400, 200)\n",
    "            \n",
    "            self.bn2 = nn.BatchNorm1d(200, momentum=0.5)\n",
    "#             self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc_age = nn.Linear(200, output_size_age)\n",
    "            self.bn_age = nn.BatchNorm1d(output_size_age, momentum=0.5)\n",
    "#             self.fc_gender = nn.Linear(hidden_dim, output_size_gender)\n",
    "          \n",
    "        self.sig = nn.Sigmoid()\n",
    "#         print(\"==before\")\n",
    "        self.reset_parameters()\n",
    "#         print(\"==after\")\n",
    "#         print(\"==emb\")\n",
    "\n",
    "        self.creative_embedding = creative_embedding\n",
    "        self.ad_embedding = ad_embedding\n",
    "        self.advertiser_embedding = advertiser_embedding\n",
    "        self.times_embedding = times_embedding\n",
    "        self.product_embedding = product_embedding\n",
    "        self.category_embedding = category_embedding\n",
    "        self.industry_embedding = industry_embedding\n",
    "        \n",
    "#         print(self.embedding)\n",
    "        \n",
    " \n",
    "    def forward(self, creative, ad, advertiser, times, product, category, industry, mask):\n",
    "        creative_in = self.creative_embedding(creative)\n",
    "        ad_in = self.ad_embedding(ad)\n",
    "        advertiser_in = self.advertiser_embedding(advertiser)\n",
    "        times_in = self.times_embedding(times)\n",
    "        product_in = self.product_embedding(product)\n",
    "        category_in = self.category_embedding(category)\n",
    "        industry_in = self.industry_embedding(industry)\n",
    "        \n",
    "        # ==========pack_pad===========\n",
    "        \n",
    "        lengths = torch.sum(mask, dim=1).int().cpu().numpy().tolist()\n",
    "        \n",
    "        lengths = torch.tensor(lengths)\n",
    "#         print(lengths)\n",
    "        _, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
    "        lengths = list(lengths[idx_sort])\n",
    "\n",
    "        # lstm1\n",
    "        creative_in = creative_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_creative = torch.nn.utils.rnn.pack_padded_sequence(creative_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, creative_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, creative_in.shape[0], self.hidden_dim))\n",
    "        out_creative, _ = self.lstm1(pack_creative, (h0, c0))\n",
    "        \n",
    "        output_padded_creative, _ = torch.nn.utils.rnn.pad_packed_sequence(out_creative, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_creative = output_padded_creative.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out1 = torch.max(output_padded_creative, 1)[0]\n",
    "        \n",
    "         # lstm2\n",
    "        ad_in = ad_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_ad = torch.nn.utils.rnn.pack_padded_sequence(ad_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, ad_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, ad_in.shape[0], self.hidden_dim))\n",
    "        out_ad, _ = self.lstm2(pack_ad, (h0, c0))\n",
    "        \n",
    "        output_padded_ad, _ = torch.nn.utils.rnn.pad_packed_sequence(out_ad, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_ad = output_padded_ad.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out2 = torch.max(output_padded_ad, 1)[0]\n",
    "        \n",
    "         # lstm3\n",
    "        advertiser_in = advertiser_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_advertiser = torch.nn.utils.rnn.pack_padded_sequence(advertiser_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, advertiser_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, advertiser_in.shape[0], self.hidden_dim))\n",
    "        out_advertiser, _ = self.lstm3(pack_advertiser, (h0, c0))\n",
    "        \n",
    "        output_padded_advertiser, _ = torch.nn.utils.rnn.pad_packed_sequence(out_advertiser, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_advertiser = output_padded_advertiser.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out3 = torch.max(output_padded_advertiser, 1)[0]\n",
    "\n",
    "         # lstm4\n",
    "        times_in = times_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_times = torch.nn.utils.rnn.pack_padded_sequence(times_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, times_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, times_in.shape[0], self.hidden_dim))\n",
    "        out_times, _ = self.lstm4(pack_times, (h0, c0))\n",
    "        \n",
    "        output_padded_times, _ = torch.nn.utils.rnn.pad_packed_sequence(out_times, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_times = output_padded_times.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out4 = torch.max(output_padded_times, 1)[0]\n",
    "\n",
    "         # lstm5\n",
    "        product_in = product_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_product = torch.nn.utils.rnn.pack_padded_sequence(product_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, product_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, product_in.shape[0], self.hidden_dim))\n",
    "        out_product, _ = self.lstm5(pack_product, (h0, c0))\n",
    "        \n",
    "        output_padded_product, _ = torch.nn.utils.rnn.pad_packed_sequence(out_product, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_product = output_padded_product.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out5 = torch.max(output_padded_product, 1)[0]\n",
    "        \n",
    "         # lstm6\n",
    "        category_in = category_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_category = torch.nn.utils.rnn.pack_padded_sequence(category_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, category_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, category_in.shape[0], self.hidden_dim))\n",
    "        out_category, _ = self.lstm6(pack_category, (h0, c0))\n",
    "        \n",
    "        output_padded_category, _ = torch.nn.utils.rnn.pad_packed_sequence(out_category, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_category = output_padded_category.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out6 = torch.max(output_padded_category, 1)[0]\n",
    "        \n",
    "         # lstm7\n",
    "        industry_in = industry_in.index_select(0, trans_to_device(idx_sort))  # 按下标取元素 \n",
    "        \n",
    "#         pack = torch.nn.utils.rnn.pack_padded_sequence(hidden_in, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_industry = torch.nn.utils.rnn.pack_padded_sequence(industry_in, lengths, batch_first=True)\n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        h0 = trans_to_device(torch.randn(self.n_layers*number, industry_in.shape[0], self.hidden_dim))\n",
    "        c0 = trans_to_device(torch.randn(self.n_layers*number, industry_in.shape[0], self.hidden_dim))\n",
    "        out_industry, _ = self.lstm7(pack_industry, (h0, c0))\n",
    "        \n",
    "        output_padded_industry, _ = torch.nn.utils.rnn.pad_packed_sequence(out_industry, batch_first=True)\n",
    "        \n",
    "        #还原tensor\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "        output_padded_industry = output_padded_industry.index_select(0, trans_to_device(idx_unsort))\n",
    "        \n",
    "\n",
    "        final_out7 = torch.max(output_padded_industry, 1)[0]\n",
    "        \n",
    "       \n",
    "        # dropout and fully-connected layer\n",
    "#         out1 = self.dropout3(final_out1)\n",
    "#         out2 = self.dropout3(final_out2)\n",
    "#         out3 = self.dropout3(final_out3)\n",
    "#         out = final_out\n",
    "\n",
    "#         out1 = self.dropout(final_out1)\n",
    "\n",
    "        out = torch.cat([final_out1, final_out2, final_out3, final_out4, final_out5, final_out6, final_out7], 1)\n",
    "    \n",
    "        final_out1 = self.dropout1(out)\n",
    "        final_out1 = self.bn0(final_out1)\n",
    "        \n",
    "        final_out1 = self.fc1(final_out1)\n",
    "        final_out1 = self.bn1(final_out1)\n",
    "        final_out1 = torch.relu(final_out1)\n",
    "        final_out1 = self.dropout2(final_out1)\n",
    "        \n",
    "        final_out1 = self.fc2(final_out1)\n",
    "        final_out1 = self.bn2(final_out1)\n",
    "        final_out1 = torch.relu(final_out1)\n",
    "        final_out1 = self.dropout3(final_out1)\n",
    "\n",
    "        final_out1 = self.fc_age(final_out1)\n",
    "        final_out1 = self.bn_age(final_out1)\n",
    "        final_out1 = torch.tanh(final_out1)\n",
    "\n",
    "        return final_out1\n",
    "#         return torch.tanh(out_age)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # print(\"调用\")\n",
    "        import math\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_dim)\n",
    "        for weight in self.parameters():\n",
    "            # print(\"===stdv===\")\n",
    "            # print(stdv)\n",
    "#             print(weight)\n",
    "            weight.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "    \n",
    "    melo_batch_size = 512\n",
    "    output_size_age = 10\n",
    "    output_size_gender = 2\n",
    "    embedding_dim = 300\n",
    "    hidden_dim = 100\n",
    "    n_layers = 2\n",
    "    bidirectional = False  #这里为True，为双向LSTM\n",
    " \n",
    "    model = trans_to_device(BiLSTM(output_size_age, output_size_gender, embedding_dim, hidden_dim, n_layers, bidirectional))\n",
    "#     model = torch.load('/DATA/zhouyongyu/model_save/w2v32_age_model/age_initmodel_epoch_14.pkl')\n",
    "#     model = trans_to_device(model)\n",
    "    print(model)\n",
    "    \n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_age_acc = 0\n",
    "    last_model_name = ''\n",
    "    \n",
    "    for epoch in tqdm(range(50)):\n",
    "        model.train()\n",
    "        slices, creative, ad, advertiser, times, product, category, industry, mask, age, gender = \\\n",
    "            generate_batch(train_creative, train_ad, train_advertiser, train_times, train_product, train_category, train_industry, train_mask, train_age, train_gender, batch_size=melo_batch_size)\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        for slice in slices:\n",
    "\n",
    "            # print(slice)\n",
    "\n",
    "            # time.sleep(5)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            creative_melo, ad_melo, advertiser_melo, times_melo, product_melo, category_melo, industry_melo, mask_melo, age_melo, gender_melo = \\\n",
    "                get_slice(creative, ad, advertiser, times, product, category, industry, mask, age, gender, batch_index=slice)\n",
    "\n",
    "#             print(\"======batch\" + str(count + 1))\n",
    "            count += 1\n",
    "            \n",
    "            creative_melo = trans_to_device(torch.Tensor(creative_melo).long())\n",
    "            ad_melo = trans_to_device(torch.Tensor(ad_melo).long())\n",
    "            advertiser_melo = trans_to_device(torch.Tensor(advertiser_melo).long())\n",
    "            times_melo = trans_to_device(torch.Tensor(times_melo).long())\n",
    "            product_melo = trans_to_device(torch.Tensor(product_melo).long())\n",
    "            category_melo = trans_to_device(torch.Tensor(category_melo).long())\n",
    "            industry_melo = trans_to_device(torch.Tensor(industry_melo).long())\n",
    "            age_melo = trans_to_device(torch.Tensor(age_melo).long())\n",
    "            gender_melo = trans_to_device(torch.Tensor(gender_melo).long())\n",
    "            mask_melo = trans_to_device(torch.Tensor(mask_melo).float())\n",
    "            \n",
    "            out_age = model(creative_melo, ad_melo, advertiser_melo, times_melo, product_melo, category_melo, industry_melo, mask_melo)\n",
    "            \n",
    "#             print(out_age.size())\n",
    "#             print(age_melo.size())\n",
    "#             print(age_melo - 1)\n",
    "            loss_age = loss_function(out_age, age_melo - 1)\n",
    "#             print(out_gender.size())\n",
    "#             print(gender_melo.size())\n",
    "#             print(gender_melo - 1)\n",
    "#             loss_gender = loss_function(out_gender, gender_melo - 1)\n",
    "            \n",
    "            loss = loss_age\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "#             print('[%d/%d] Loss: %.4f' % (count, len(slices), loss.item()))\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print('\\tLoss:\\t%.3f' % total_loss)\n",
    "        \n",
    "        print(\"begin model.eval\")\n",
    "        model.eval()\n",
    "        \n",
    "        age_acc = 0\n",
    "        gender_acc = 0\n",
    "        \n",
    "        slices, creative, ad, advertiser, times, product, category, industry, mask, age, gender = \\\n",
    "            generate_batch(test_creative, test_ad, test_advertiser, test_times, test_product, test_category, test_industry, test_mask, test_age, test_gender, batch_size=melo_batch_size)\n",
    "        \n",
    "        \n",
    "        hit_age = []\n",
    "        hit_gender = []\n",
    "        \n",
    "        for slice in slices:\n",
    "\n",
    "            # print(slice)\n",
    "\n",
    "            # time.sleep(5)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            creative_melo, ad_melo, advertiser_melo, times_melo, product_melo, category_melo, industry_melo, mask_melo, age_melo, gender_melo = \\\n",
    "                get_slice(creative, ad, advertiser, times, product, category, industry, mask, age, gender, batch_index=slice)\n",
    "            \n",
    "#             print(\"======batch\" + str(count + 1))\n",
    "            count += 1\n",
    "            \n",
    "            creative_melo = trans_to_device(torch.Tensor(creative_melo).long())\n",
    "            ad_melo = trans_to_device(torch.Tensor(ad_melo).long())\n",
    "            advertiser_melo = trans_to_device(torch.Tensor(advertiser_melo).long())\n",
    "            times_melo = trans_to_device(torch.Tensor(times_melo).long())\n",
    "            product_melo = trans_to_device(torch.Tensor(product_melo).long())\n",
    "            category_melo = trans_to_device(torch.Tensor(category_melo).long())\n",
    "            industry_melo = trans_to_device(torch.Tensor(industry_melo).long())\n",
    "            age_melo = trans_to_device(torch.Tensor(age_melo).long())\n",
    "            gender_melo = trans_to_device(torch.Tensor(gender_melo).long())\n",
    "            mask_melo = trans_to_device(torch.Tensor(mask_melo).float())\n",
    "            \n",
    "            out_age = model(creative_melo, ad_melo, advertiser_melo, times_melo, product_melo, category_melo, industry_melo, mask_melo)\n",
    "            \n",
    "            \n",
    "            out_age = torch.nn.functional.log_softmax(out_age, dim=1)\n",
    "#             out_gender = torch.nn.functional.log_softmax(out_gender, dim=1)\n",
    "\n",
    "#             print(out_age)\n",
    "            pred_age = out_age.argmax(1)\n",
    "#             print(pred_age)\n",
    "#             pred_gender = out_gender.argmax(1)\n",
    "\n",
    "#             print(age_melo)\n",
    "            correct_age = (pred_age == age_melo-1).sum()\n",
    "#             print(correct_age)\n",
    "#             correct_gender = (pred_gender == gender_melo-1).sum()\n",
    "#             print(correct_gender)\n",
    "            \n",
    "            age_acc += correct_age.item()\n",
    "#             print(age_acc)\n",
    "#             gender_acc += correct_gender.item()\n",
    "        \n",
    "        print('\\tage_acc:\\t%.5f' % (float(age_acc)/len(creative)))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_age_acc = float(age_acc)/len(creative)\n",
    "            print(\"save model\")\n",
    "            last_model_name = '1_copy_age_initmodel_7input_epoch_%s.pkl_%.5f'% (str(epoch), (float(age_acc)/len(creative)))\n",
    "            torch.save(model, '/DATA/zhouyongyu/model_save/w2v32_age_model/' + last_model_name)\n",
    "        else:\n",
    "            if float(age_acc)/len(creative) >= best_age_acc:\n",
    "                best_age_acc = float(age_acc)/len(creative)\n",
    "                os.remove('/DATA/zhouyongyu/model_save/w2v32_age_model/' + last_model_name)\n",
    "                last_model_name = '1_copy_age_initmodel_7input_epoch_%s.pkl_%.5f'% (str(epoch), (float(age_acc)/len(creative)))\n",
    "                print(\"save model\")\n",
    "                torch.save(model, '/DATA/zhouyongyu/model_save/w2v32_age_model/' + last_model_name)\n",
    "#         print('\\tgender_acc:\\t%.3f' % (float(gender_acc)/len(input)))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_mask = np.array(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  9 14 ... 13 89 12]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np_mask, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.min(np.sum(np_mask, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0113,  0.0845,  0.8785, -0.6062],\n",
      "        [-0.7693, -1.1818,  0.1705, -1.2648],\n",
      "        [-0.2886, -1.6722, -0.0205,  0.7305]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0113,  0.0845,  0.8785, -0.6062])\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[2, 3, 1],[2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(a.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =torch.Tensor([[4,1,2],[3,4,5]])\n",
    "torch.max(a,1)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zyy] *",
   "language": "python",
   "name": "conda-env-zyy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
