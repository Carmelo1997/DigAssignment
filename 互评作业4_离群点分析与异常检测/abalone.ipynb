{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据挖掘互评作业四：离群点分析与异常检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学院：计算机学院&emsp;学号：3120191079&emsp;姓名：周泳宇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abalone数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、算法介绍与引入\n",
    "\n",
    "## 使用PyOD来做离群点检测，使用的是离群得分，即每个模型都会给每个数据点打分而非直接根据一个阈值判定某个点是否为离群点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一个数组来保存下述所有的算法分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Angle_Based Outlier Detection (ABOD)\n",
    "### 它考虑了每个数据点和其邻居的关系，但是不考虑邻居之间的关系。ABOD在多维度数据上表现较好，PyOD提供了两种不同版本的ABOD，Fast ABOD：使用KNN来近似，Original ABOD：以高时间复杂度来考虑所有训练数据点，这里采用Original ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.abod import ABOD\n",
    "clf_ABOD = ABOD()\n",
    "clfs.append([\"ABOD\", clf_ABOD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 KNN 检测器\n",
    "### 对于任意数据点，其到第k个邻居的距离可以作为其离群得分，PyOD提供三种不同的KNN检测器：Largest： 使用第k个邻居的距离来作为离群得分；Mean: 使用全部k个邻居的平均距离作为离群得分；Median:使用k个邻居的距离的中位数作为离群得分。这里采用Largest检测器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "clf_KNN = KNN()\n",
    "clfs.append([\"KNN\", clf_KNN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Isolation Forest\n",
    "### 内部使用sklearn，此方法中，使用一个集合的树来完成数据分区。Isolation Forest提供一个离群得分来判定一个数据点在结构中有多孤立。其离群得分用来将它与正常观测数据区分开来。Isolation Forest在多维数据上表现很好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "clf_IForest = IForest()\n",
    "clfs.append([\"IForest\", clf_IForest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Histogram-based Outiler Detection\n",
    "### 一种高效的无监督方法，它假设特征之间独立，然后通过构建直方图来计算离群得分，比多变量方法快得多，但是要损失一些精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "clf_HBOS = HBOS()\n",
    "clfs.append([\"HBOS\", clf_HBOS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Local Outlier Factor(LOF)\n",
    "### LOF算法（Local Outlier Factor，局部离群因子检测方法），是一种无监督的离群检测方法，是基于密度的离群点检测方法中一个比较有代表性的算法。该算法会给数据集中的每个点计算一个离群因子LOF，通过判断LOF是否接近于1来判定是否是离群因子。若LOF远大于1，则认为是离群因子，接近于1，则是正常点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "clf_LOF = LOF()\n",
    "clfs.append([\"LOF\", clf_LOF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Clustering Based Local Outiler Factor\n",
    "### 它将数据分为小聚类簇和大聚类簇。离群得分基于数据点所属的聚类簇的大小来计算，距离计算方式为到最近大聚类簇的距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "clf_CBLOF = CBLOF()\n",
    "clfs.append([\"CBLOF\", clf_CBLOF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、读入所有数据集并进行离群点分析与异常检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思路如下：对于所有单个的benchmark，每次读入一个benchmark，然后进行训练集与测试集划分，并用上述6个检测算法进行训练与测试，记录在训练集与测试集上的评估指标（roc与prn），并记录下来，最后用表格进行展示（因benchmark太多，故这里不作图，只用表格展示）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 首先展示对单个benchmark的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./abalone/benchmarks/abalone_benchmark_0001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point.id</th>\n",
       "      <th>motherset</th>\n",
       "      <th>origin</th>\n",
       "      <th>original.label</th>\n",
       "      <th>diff.score</th>\n",
       "      <th>ground.truth</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_point_1584</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>7</td>\n",
       "      <td>0.153312</td>\n",
       "      <td>nominal</td>\n",
       "      <td>-0.116511</td>\n",
       "      <td>-0.129799</td>\n",
       "      <td>-0.227518</td>\n",
       "      <td>-0.461352</td>\n",
       "      <td>-0.353066</td>\n",
       "      <td>-0.342963</td>\n",
       "      <td>-0.551935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abalone_point_0315</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>23</td>\n",
       "      <td>0.202253</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.777094</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.960988</td>\n",
       "      <td>0.333986</td>\n",
       "      <td>1.039157</td>\n",
       "      <td>1.588828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abalone_point_1779</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>8</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>nominal</td>\n",
       "      <td>-0.283048</td>\n",
       "      <td>-0.532863</td>\n",
       "      <td>0.489721</td>\n",
       "      <td>0.103505</td>\n",
       "      <td>-0.048961</td>\n",
       "      <td>0.313886</td>\n",
       "      <td>0.313709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone_point_1926</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>11</td>\n",
       "      <td>0.209155</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.625945</td>\n",
       "      <td>0.609261</td>\n",
       "      <td>0.713225</td>\n",
       "      <td>0.930932</td>\n",
       "      <td>0.893190</td>\n",
       "      <td>0.396322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone_point_0588</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>13</td>\n",
       "      <td>0.163268</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>0.216565</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.131102</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.224666</td>\n",
       "      <td>0.090375</td>\n",
       "      <td>0.080237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             point.id motherset      origin  original.label  diff.score  \\\n",
       "0  abalone_point_1584   abalone  regression               7    0.153312   \n",
       "1  abalone_point_0315   abalone  regression              23    0.202253   \n",
       "2  abalone_point_1779   abalone  regression               8    0.562701   \n",
       "3  abalone_point_1926   abalone  regression              11    0.209155   \n",
       "4  abalone_point_0588   abalone  regression              13    0.163268   \n",
       "\n",
       "  ground.truth        V1        V2        V3        V4        V5        V6  \\\n",
       "0      nominal -0.116511 -0.129799 -0.227518 -0.461352 -0.353066 -0.342963   \n",
       "1      anomaly  0.882716  0.777094  0.848341  0.960988  0.333986  1.039157   \n",
       "2      nominal -0.283048 -0.532863  0.489721  0.103505 -0.048961  0.313886   \n",
       "3      anomaly  0.716178  0.625945  0.609261  0.713225  0.930932  0.893190   \n",
       "4      anomaly  0.216565  0.021350  0.131102 -0.000494 -0.224666  0.090375   \n",
       "\n",
       "         V7  \n",
       "0 -0.551935  \n",
       "1  1.588828  \n",
       "2  0.313709  \n",
       "3  0.396322  \n",
       "4  0.080237  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将是否离群转换为数字标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "           'nominal': 0,\n",
    "           'anomaly': 1}\n",
    "df['ground.truth'] = df['ground.truth'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point.id</th>\n",
       "      <th>motherset</th>\n",
       "      <th>origin</th>\n",
       "      <th>original.label</th>\n",
       "      <th>diff.score</th>\n",
       "      <th>ground.truth</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_point_1584</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>7</td>\n",
       "      <td>0.153312</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116511</td>\n",
       "      <td>-0.129799</td>\n",
       "      <td>-0.227518</td>\n",
       "      <td>-0.461352</td>\n",
       "      <td>-0.353066</td>\n",
       "      <td>-0.342963</td>\n",
       "      <td>-0.551935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abalone_point_0315</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>23</td>\n",
       "      <td>0.202253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.777094</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.960988</td>\n",
       "      <td>0.333986</td>\n",
       "      <td>1.039157</td>\n",
       "      <td>1.588828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abalone_point_1779</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>8</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.283048</td>\n",
       "      <td>-0.532863</td>\n",
       "      <td>0.489721</td>\n",
       "      <td>0.103505</td>\n",
       "      <td>-0.048961</td>\n",
       "      <td>0.313886</td>\n",
       "      <td>0.313709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone_point_1926</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>11</td>\n",
       "      <td>0.209155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.625945</td>\n",
       "      <td>0.609261</td>\n",
       "      <td>0.713225</td>\n",
       "      <td>0.930932</td>\n",
       "      <td>0.893190</td>\n",
       "      <td>0.396322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone_point_0588</td>\n",
       "      <td>abalone</td>\n",
       "      <td>regression</td>\n",
       "      <td>13</td>\n",
       "      <td>0.163268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216565</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.131102</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.224666</td>\n",
       "      <td>0.090375</td>\n",
       "      <td>0.080237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             point.id motherset      origin  original.label  diff.score  \\\n",
       "0  abalone_point_1584   abalone  regression               7    0.153312   \n",
       "1  abalone_point_0315   abalone  regression              23    0.202253   \n",
       "2  abalone_point_1779   abalone  regression               8    0.562701   \n",
       "3  abalone_point_1926   abalone  regression              11    0.209155   \n",
       "4  abalone_point_0588   abalone  regression              13    0.163268   \n",
       "\n",
       "   ground.truth        V1        V2        V3        V4        V5        V6  \\\n",
       "0             0 -0.116511 -0.129799 -0.227518 -0.461352 -0.353066 -0.342963   \n",
       "1             1  0.882716  0.777094  0.848341  0.960988  0.333986  1.039157   \n",
       "2             0 -0.283048 -0.532863  0.489721  0.103505 -0.048961  0.313886   \n",
       "3             1  0.716178  0.625945  0.609261  0.713225  0.930932  0.893190   \n",
       "4             1  0.216565  0.021350  0.131102 -0.000494 -0.224666  0.090375   \n",
       "\n",
       "         V7  \n",
       "0 -0.551935  \n",
       "1  1.588828  \n",
       "2  0.313709  \n",
       "3  0.396322  \n",
       "4  0.080237  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取训练属性与标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_n = ['V1','V2','V3', 'V4','V5','V6', 'V7', 'ground.truth']\n",
    "\n",
    "data = pd.DataFrame(df,columns = col_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集（80%）与测试集（20%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据转换成np.array()并用分类器进行检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
       "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "  radius=1.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_name = 'KNN'\n",
    "clf = KNN()\n",
    "clf.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "# get the prediction on the test data\n",
    "y_test_pred = clf.predict(x_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(x_test)  # outlier scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用roc和prn评价准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from pyod.utils.utility import precision_n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_roc = np.round(roc_auc_score(y_train, y_train_pred), decimals=4)\n",
    "train_prn = np.round(precision_n_scores(y_train, y_train_pred), decimals=4)\n",
    "test_roc = np.round(roc_auc_score(y_test, y_test_pred), decimals=4)\n",
    "test_prn = np.round(precision_n_scores(y_test, y_test_pred), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514\n",
      "0.5629\n",
      "0.527\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "print(train_roc)\n",
    "print(train_prn)\n",
    "print(test_roc)\n",
    "print(test_prn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 展示用多个算法对批量数据进行检测与评价（有些benchmark的训练集或测试集只有全为异常值或全为非异常值，无法用roc_auc_score进行评价，故设为0）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新建一个dict，用于保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1725/1725 [49:21<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "result = dict()\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "files = os.listdir('./abalone/benchmarks')\n",
    "# files[315:330]\n",
    "for file in tqdm(files):\n",
    "#     print(file)\n",
    "    df = pd.read_csv('./abalone/benchmarks/' + file)\n",
    "    \n",
    "    label_mapping = {\n",
    "           'nominal': 0,\n",
    "           'anomaly': 1}\n",
    "    df['ground.truth'] = df['ground.truth'].map(label_mapping)\n",
    "    \n",
    "    col_n = ['V1','V2','V3', 'V4','V5','V6', 'V7', 'ground.truth']\n",
    "    data = pd.DataFrame(df,columns = col_n)\n",
    "    \n",
    "    x = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1:]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    for clf_item in clfs:\n",
    "#         print(clf_item)\n",
    "        clf_name = clf_item[0]\n",
    "        clf = clf_item[1]\n",
    "        clf.fit(x_train)\n",
    "        \n",
    "        y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "        y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "        # get the prediction on the test data\n",
    "        y_test_pred = clf.predict(x_test)  # outlier labels (0 or 1)\n",
    "        y_test_scores = clf.decision_function(x_test)  # outlier scores\n",
    "        \n",
    "        try:\n",
    "            train_roc = np.round(roc_auc_score(y_train, y_train_pred), decimals=4)\n",
    "        except:\n",
    "            train_roc = 0.0\n",
    "#         train_roc = np.round(roc_auc_score(y_train, y_train_scores), decimals=4)\n",
    "        train_prn = np.round(precision_n_scores(y_train, y_train_pred), decimals=4)\n",
    "        try:\n",
    "            test_roc = np.round(roc_auc_score(y_test, y_test_pred), decimals=4)\n",
    "        except:\n",
    "            test_roc = 0.0\n",
    "#         test_roc = np.round(roc_auc_score(y_test, y_test_scores), decimals=4)\n",
    "        test_prn = np.round(precision_n_scores(y_test, y_test_pred), decimals=4)\n",
    "        \n",
    "        try:\n",
    "            result[file]\n",
    "            result[file][clf_name] = [train_roc, train_prn, test_roc, test_prn]\n",
    "        except:\n",
    "            result[file] = {}\n",
    "            result[file][clf_name] = [train_roc, train_prn, test_roc, test_prn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1725/1725 [00:45<00:00, 37.88it/s]\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(columns=['benchmark', 'clf_name', 'train_roc', 'train_prn', 'test_roc', 'test_prn'])\n",
    "\n",
    "for benchmark in tqdm(result):\n",
    "    for clf_name in result[benchmark]:\n",
    "        values = result[benchmark][clf_name]\n",
    "        train_roc = values[0]\n",
    "        train_prn = values[1]\n",
    "        test_roc = values[2]\n",
    "        test_prn = values[3]\n",
    "        \n",
    "        c = {\"benchmark\": benchmark, \"clf_name\": clf_name, \"train_roc\": train_roc, \n",
    "             \"train_prn\": train_prn, \"test_roc\": test_roc, \"test_prn\": test_prn}\n",
    "#         print(c)\n",
    "\n",
    "        insertRow = pd.DataFrame(c, columns=['benchmark', 'clf_name', 'train_roc', 'train_prn', 'test_roc', 'test_prn'],index = [0])\n",
    "#         print(insertRow)\n",
    "\n",
    "        result_df = result_df.append(insertRow)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 结果如下表所示，详细结果见附件：abalone_result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>clf_name</th>\n",
       "      <th>train_roc</th>\n",
       "      <th>train_prn</th>\n",
       "      <th>test_roc</th>\n",
       "      <th>test_prn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_0001.csv</td>\n",
       "      <td>ABOD</td>\n",
       "      <td>0.5613</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.5814</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_0001.csv</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_0001.csv</td>\n",
       "      <td>IForest</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_0001.csv</td>\n",
       "      <td>HBOS</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_0001.csv</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.5181</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_1800.csv</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4406</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_1800.csv</td>\n",
       "      <td>IForest</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_1800.csv</td>\n",
       "      <td>HBOS</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_1800.csv</td>\n",
       "      <td>LOF</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_benchmark_1800.csv</td>\n",
       "      <td>CBLOF</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     benchmark clf_name  train_roc  train_prn  test_roc  \\\n",
       "0   abalone_benchmark_0001.csv     ABOD     0.5613     0.7881    0.5814   \n",
       "0   abalone_benchmark_0001.csv      KNN     0.5546     0.7550    0.5734   \n",
       "0   abalone_benchmark_0001.csv  IForest     0.5162     0.5629    0.5180   \n",
       "0   abalone_benchmark_0001.csv     HBOS     0.5427     0.6954    0.5524   \n",
       "0   abalone_benchmark_0001.csv      LOF     0.5135     0.5497    0.5181   \n",
       "..                         ...      ...        ...        ...       ...   \n",
       "0   abalone_benchmark_1800.csv      KNN     0.4570     0.0000    0.4406   \n",
       "0   abalone_benchmark_1800.csv  IForest     0.4631     0.0000    0.4533   \n",
       "0   abalone_benchmark_1800.csv     HBOS     0.4992     0.0000    0.4733   \n",
       "0   abalone_benchmark_1800.csv      LOF     0.4510     0.0000    0.4315   \n",
       "0   abalone_benchmark_1800.csv    CBLOF     0.4570     0.0000    0.4492   \n",
       "\n",
       "    test_prn  \n",
       "0     0.9167  \n",
       "0     0.8857  \n",
       "0     0.5789  \n",
       "0     0.7568  \n",
       "0     0.5750  \n",
       "..       ...  \n",
       "0     0.0000  \n",
       "0     0.0588  \n",
       "0     0.0938  \n",
       "0     0.0000  \n",
       "0     0.0345  \n",
       "\n",
       "[10350 rows x 6 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('./abalone_result.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 分析：可以看到针对不同的数据集，不同的算法各有优劣。因此，在实际使用过程中，需要针对具体的场景，选择合适的异常点检测算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、总结\n",
    "## 1.LOF类的算法适用于局部区域空间问题，对于完整区域空间，KNN和Iforest更好。\n",
    "\n",
    "## 2.KNN每次运行需要遍历所有数据，所以效率比较低，如果效率要求比较高，用聚类方法更好。\n",
    "\n",
    "## 3.传统机器学习算法中Iforest、KNN表现较好。\n",
    "\n",
    "## 4.对于不同种类的数据，没有哪一种算法是最好的，HBOS算法在某些数据集上的表现非常好，且运算速度很快。\n",
    "\n",
    "## 5.当数据特征数很多时，只有KNN表现还不错，Iforest表现也不好，因为特征选取的随机性，可能无法覆盖足够多的特征（不绝对）。\n",
    "\n",
    "## 6.ABOD综合效果最差，尽量不要用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env]",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
